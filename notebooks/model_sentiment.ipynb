{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Union\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import sklearn\n",
    "import transformers\n",
    "\n",
    "repo_dir = Path(subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"]).decode().strip())\n",
    "data_dir = repo_dir / \"data\"\n",
    "sys.path.append(str(repo_dir))\n",
    "from src import bert, train, optim, engine\n",
    "\n",
    "plt.style.use('Solarize_Light2')\n",
    "%config InlineBackend.figure_format='retina'\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>negative</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>negative</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>negative</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>negative</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "0      neutral  According to Gran , the company has no plans t...\n",
       "1      neutral  Technopolis plans to develop in stages an area...\n",
       "2     negative  The international electronic industry company ...\n",
       "3     positive  With the new production plant the company woul...\n",
       "4     positive  According to the company 's updated strategy f...\n",
       "...        ...                                                ...\n",
       "4841  negative  LONDON MarketWatch -- Share prices ended lower...\n",
       "4842   neutral  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4844  negative  Net sales of the Paper segment decreased to EU...\n",
       "4845  negative  Sales in Finland decreased by 10.5 % in Januar...\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fp = data_dir / \"all-data.csv\"\n",
    "model_dir = repo_dir / \"models/sentiment\"\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "data = pd.read_csv(\n",
    "    data_fp,\n",
    "    names=[\"label\", \"text\"],\n",
    "    encoding=\"cp866\",\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words_amount = data[\"text\"].str.split().apply(len)\n",
    "data = data[text_words_amount >= 5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data\n",
    "\n",
    "X = data_sample[[\"text\"]]\n",
    "y = data_sample[\"label\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert + boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bert inference on 3224 texts: 100%|██████████| 33/33 [00:04<00:00,  6.74it/s]\n",
      "Bert inference on 1612 texts: 100%|██████████| 17/17 [00:01<00:00, 16.35it/s]\n",
      "Bert inference on 3224 texts: 100%|██████████| 33/33 [00:00<00:00, 237.27it/s]\n",
      "Bert inference on 1612 texts: 100%|██████████| 17/17 [00:00<00:00, 1115.19it/s]\n",
      "Bert inference on 3224 texts: 100%|██████████| 33/33 [00:01<00:00, 29.30it/s] \n",
      "Bert inference on 1612 texts: 100%|██████████| 17/17 [00:00<00:00, 17.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'acc': [0.565136476426799,\n",
       "              0.7779156327543424,\n",
       "              0.5942928039702233],\n",
       "             'f1': [0.45035519426846204,\n",
       "              0.5929626383428066,\n",
       "              0.38225300031016324]})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_vectorizer = bert.BertVectorizer(\n",
    "    bert_name=\"distilbert-base-uncased\",\n",
    ")\n",
    "col_transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"bert_vectorizer\", bert_vectorizer, \"text\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = LGBMClassifier(\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"features\", col_transformer),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "metrics_dict = train.train_and_cross_validate(pipeline, X, y, split_type=\"kfold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4751902776404773"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metrics_dict[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/natitov/workflow/hse-financial-tonality/models/tonality/model.pkl']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, model_dir / \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2227cee75ea54c7bbb4cdcb29c2bd466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bert inference on 485 texts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pipeline = joblib.load(model_dir / \"model.pkl\")\n",
    "pred_test = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix = sklearn.metrics.confusion_matrix(y_test, pred_test)\n",
    "\n",
    "# confusion_matrix_display = sklearn.metrics.ConfusionMatrixDisplay(\n",
    "#     confusion_matrix,\n",
    "#     display_labels=pipeline.named_steps['model']._classes,\n",
    "# ).plot()\n",
    "\n",
    "# confusion_matrix_display.ax_.grid(False);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "class VaderPredictor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        output = np.full(\n",
    "            X.shape[0],\n",
    "            \"\",\n",
    "            dtype=\"object\",\n",
    "        )\n",
    "        for i, sentence in enumerate(X.values.flatten()):\n",
    "            output[i] = self.get_sentiment(sentence)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_sentiment(self, sentence):\n",
    "        sentiment_dict = self.vader.polarity_scores(sentence)\n",
    "\n",
    "        if sentiment_dict[\"compound\"] >= 0.05:\n",
    "            overall_sentiment = \"positive\"\n",
    "        elif sentiment_dict[\"compound\"] <= -0.05:\n",
    "            overall_sentiment = \"negative\"\n",
    "        else:\n",
    "            overall_sentiment = \"neutral\"\n",
    "\n",
    "        return overall_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5430107526881721, 'f1': 0.4308794343578661}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = VaderPredictor()\n",
    "\n",
    "metrics_dict = train.train_and_cross_validate(pipeline, X, y, split_type=\"kfold\")\n",
    "{metric_type: round(np.mean(metrics), 2) for metric_type, metrics in metrics_dict.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focal_loss import FocalLoss\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model = bert.BertFineTuned(use_softmax_in_forward=True)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "label_rates = data[\"label\"].value_counts() / data.shape[0]\n",
    "label_rates = label_rates.sort_index()\n",
    "weights = [1 / rate for rate in label_rates]\n",
    "\n",
    "criterion = FocalLoss(\n",
    "    gamma=1,\n",
    "    weights=torch.tensor(weights, device=device),\n",
    ")\n",
    "\n",
    "milestones = [15]\n",
    "lr = 0.005\n",
    "\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fff79c5af1345d8a5050ef6257e809b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training::   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.65\n",
      "f1: 0.54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509f4036bf2b4603a14c89bd0248e8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training::   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.70\n",
      "f1: 0.58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d0dffe4c184003b9eaab4ba322b14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training::   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.60\n",
      "f1: 0.50\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = bert.train_bert_and_cross_validate(\n",
    "    model,\n",
    "    criterion=criterion,\n",
    "    lr=lr,\n",
    "    milestones=milestones,\n",
    "    epochs=epochs,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    device=device,\n",
    "    split_type=\"kfold\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.69, 'f1': 0.55}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{metric_type: round(np.mean(metrics), 2) for metric_type, metrics in metrics_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
